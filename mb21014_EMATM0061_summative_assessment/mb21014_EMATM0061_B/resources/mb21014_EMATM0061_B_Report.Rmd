---
title: "mb21014_EMATM0061_B_Report"
author: "Fengfan Hu"
date: "21/12/2021"
output:
  html_document: default
---

## Section B
```{r, message=FALSE}
# Load package
library(tidyverse)
```

### B.1

In this question we consider a security system at a factory. A sensor is designed to make a sound if a person walks within one metre of the gate. However, the sensor is not perfectly reliable: It sometimes makes a sound when there is no one present, and sometimes fails to make a sound when someone is present.

For simplicity we will view the passage of time as being broken down into a series of phases lasting exactly one minute. For each minute, we let $p_0$ denote the conditional probability that the sensor makes a sound if there is no person within one metre of the gate, during that minute. Moreover, for each minute, we let $p_1$ denote the conditional probability that the sensor makes a sound at least once, if there is at least one person present, during that minute. Suppose also that the probability that at least one person walks within one metre of the gate over any given minute is q. Again, for simplicity, we assume that $p_0,p_1,q \in [0,1]$ are all constant. Let $\phi$ denote the conditional probability that at least one person has passed within one metre of the gate during the current minute, given that the alarm has made a sound during that minute.

#### (a)
**(Question)**Write a function called c_prob_person_given_alarm which gives $\phi$ as a function of $p_0,p_1$ and q.

**(Answer)**
According to Bayes theorem, we have $\mathbb{P(\phi)=\frac{p_1\cdot q}{p_1\cdot q+p_0\cdot (1-q)}}$
```{r}
c_prob_person_given_alarm <- function(p0, p1, q) {
  return ((p1*q)/(p1*q+p0*(1-q)))
}
```

#### (b)
**(Question)**Consider a setting in which $p_0$ = 0.05, $p_1$ = 0.95 and q = 0.1. In this case, what is $\phi$?

**(Answer)**Compute conditional probability that at least one person has passed within one metre of the gate during the current minute, given that the alarm has made a sound during that minute.
```{r}
p0 <- 0.05
p1 <- 0.95
q <- 0.1
phi <- c_prob_person_given_alarm(p0, p1, q)
phi
```

#### (c)
**(Question)**Next consider a setting in which $p_0$ = 0.05, $p_1$ = 0.95 and generate a plot which shows $\phi$ as we vary q. That is, you should display a curve which has q along the horizontal axis and the corresponding value of $\phi$ along the vertical axis.  

**(Answer)**
```{r}
# q sequence from 0 to 1 with step 0.01.
q_sequence <- seq(0, 1, 0.01)
# Implement each q to the function to get the conditional probability.
phi_sequence <- map_dbl(q_sequence, ~c_prob_person_given_alarm(p0, p1, .x)) 
# Draw the plot
ggplot(data=data.frame(q=q_sequence, phi=phi_sequence)) + geom_line(aes(x=q, y=phi)) + theme_bw()
```

------

### B.2
Suppose that $\alpha, \beta, \gamma \in [0,1]$ with $\alpha+\beta+\gamma \le1$ and let X be a discrete random variable with with distribution supported on $\{0, 1, 2, 5\}$. Suppose that $P(X = 1) = \alpha, P (X = 2) = \beta, P (X = 5) = \gamma$ and $P(X \notin \{0, 1, 2, 5\}) = 0$.

#### (a)
**(Question)**What is the probability mass function $p_X: \mathbb{R} \rightarrow [0,1]$ for X?  

**(Answer)**
$$p(x)= \begin{cases}
  1-\alpha-\beta-\gamma & \text{ if } x= 0 \\
  \alpha & \text{ if } x= 1 \\
  \beta & \text{ if } x= 2 \\
  \gamma & \text{ if } x= 5 \\
  0 & \text{ otherwise } \\
\end{cases}$$

#### (b)
**(Question)**Give an expression for the expectation of X in terms of $\alpha, \beta, \gamma$.  

**(Answer)**
$$E(X)=\Sigma_{x\in \mathbb{R}}x \cdot p_X(x)=\alpha+2\beta+5\gamma$$

#### (c)
**(Question)**Give an expression for the population variance of X in terms of $\alpha, \beta, \gamma$.  

**(Answer)**
$$Var(X)=E(\{X-E(x)\}^2)=E(X^2)-E(X)^2=(\alpha+4\beta+25\gamma)-(\alpha+2\beta+5\gamma)^2=\alpha+4\beta+25\gamma-\alpha^2-4\beta^2-25\gamma^2-4\alpha\beta-10\alpha\gamma-20\beta\gamma$$

------

Suppose $X_1, ..., X_n$ is a sample consisting of independent and identically distributed random variables with $P(X_i=1)=\alpha,P(X_i=2)=\beta,P(X_i=5)=\gamma$ and $P(X_i\notin\{0,1,2,5\})=0 \space for \space i=1,...,n$. Let $\bar{X}:= \frac{1}{n}\Sigma^{n}_{i=1}X_{i}$ be the sample mean.

#### (d)
**(Question)**Give an expression for the expectation of the random variable $\bar{X}$ in terms of $\alpha, \beta, \gamma$.  

**(Answer)**
$$E(\bar{X})=E(\frac{\Sigma_{i=1}^{n}X_i}{n})=\frac{E(\Sigma_{i=1}^{n}X_i)}{n} =\frac{\Sigma_{i=1}^{n}E(X_i)}{n}= \frac{n\cdot\mu}{n}= \mu =\alpha+2\beta+5\gamma$$

#### (e)
**(Question)**Give an expression for the population variance of the random variable $\bar{X}$ in terms of $\alpha, \beta, \gamma, n$.

**(Answer)**According to the fact that random variables are independent and identically distributed, we have
$Var(\bar{X})=Var(\frac{\Sigma_{i=1}^{n}X_i}{n})=\frac{\Sigma_{i=1}^{n}Var(X_i)}{n^2}=\frac{n\cdot\sigma}{n^2}=\frac{\sigma}{n}$, so the population variance of the random variable $\bar{X}$ is $Var(\bar{X})=\frac{\sigma}{n}=\frac{E(X^2)-E(X)^2}{n}=\frac{1}{n}\{(\alpha+4\beta+25\gamma)-(\alpha+2\beta+5\gamma)^2\}=\frac{1}{n}(\alpha+4\beta+25\gamma-\alpha^2-4\beta^2-25\gamma^2-4\alpha\beta-10\alpha\gamma-20\beta\gamma)$

#### (f)
**(Question)**Create a function called `sample_X_0125()` which takes as inputs $\alpha, \beta, \gamma$ and n and outputs a sample $X_1,...,X_n$ of independent copies of X where $P(X =1) = \alpha, P(X =2) = \beta, P(X =5) = \gamma$ and $P(X \notin \{0,1,2,5\}) = 0$.  

**(Answer)**
```{r}
sample_X_0125 <- function(alpha, beta, gamma, n) {
  sample_X<-data.frame(U=runif(n))%>%
    mutate(X=case_when(
    # from 0 to 1, then X=1
    (0<=U)&(U<alpha)~1,
    # from alpha to alpha+beta, then X=2
    (alpha<=U)&(U<alpha+beta)~2,
    # from alpha_beta to alpha+beta+gamma, then X=5
    (alpha+beta<=U)&(U<alpha+beta+gamma)~5,
    # otherwise, X=0
    (alpha+beta+gamma<=U)&(U<=1)~0))%>%
      pull(X)
  return (sample_X)
}
```

#### (g)
**(Question)**Suppose that $\alpha = 0.1, \beta = 0.2, \gamma = 0.3$. Use your function to generate a sample of size n = 100000 consisting of independent copies of X where $P(X=1) = \alpha, P(X=2) = \beta, P(X=5) = \gamma$ and $P (X \notin \{0, 1, 2, 5\}) = 0$.  

**(Answer)**
```{r}
# For replicability, we set the random seed to 0.
set.seed(0)
alpha <- 0.1
beta <- 0.2
gamma <- 0.3
n <- 100000

sample_X <- sample_X_0125(alpha, beta, gamma, n)

cat("X_bar:", mean(sample_X), "\n")
cat("Sample variance:", var(sample_X))
```
**(Question)**What value do you observe for $\bar{X}$? What value do you observe for the sample variance? Is this the type of result you expect? Explain your answer.  

**(Answer)**
Based on the answer to question (b) we have $E(X)=\alpha+2\beta+5\gamma=2.0$,  in the simulation, the average value of sample X $\bar{X}$ is 1.99323. And by question (c), we have $Var(X)=\alpha+4\beta+25\gamma-(\alpha^2+4\beta^2+25\gamma^2+4\alpha\beta+10\alpha\gamma+20\beta\gamma)=4.4$, and we get 4.390568 in the simulation. We observe that the simulation $\bar{X}$ is closed to the population mean and variance is closed to the population variance, according to the law of large numbers the value is expected.

------

#### (h)
**(Question)**Once again, take $\alpha = 0.1, \beta = 0.2, \gamma = 0.3$. Conduct a simulation study to explore the behavior of the sample mean. Your study should involve 10000 trials. In each trial, you should set n = 100 and create a sample $X_1,...,X_n$ of independent and identically distributed random variables with $P(X_i =1) = \alpha, P(X_i =2) = \beta, P(X_i =5) = \gamma$ and $P(X_i \notin \{0,1,2,5\}) = 0$ for i = 1,...,n. For each of the 10000 trials, compute the corresponding sample mean X based on $X_1, . . . , X_n$.  

**(Answer)**
```{r}
# For replicability, we set the random seed to 0.
set.seed(0)
num_trials <- 10000
sample_size<- 100
alpha <- 0.1
beta <- 0.2
gamma <- 0.3

simulation_df <- crossing(trial=seq(num_trials), sample_size=sample_size) %>% # Generate 10000 trials with 100 sample size.
  # Generate sample.
  mutate(sample_X=pmap(.l=list(trial, sample_size), .f=~sample_X_0125(alpha, beta, gamma, .y))) %>%
  # Get the average mean of each sample
  mutate(sample_mean=map_dbl(.x=sample_X, .f=mean)) 

sample_means <- simulation_df %>% pull(sample_mean)
```

#### (i)  

**(Question)**Generate a histogram plot which displays the behavior of the sample mean within your simulation study. Use a bin width of 0.02. The height of each bar should correspond to the number of times the sample mean took on a value within the corresponding bin.  

**(Answer)**
```{r}
# Draw a histogram plot
ggplot(data=data.frame(sample_means=sample_means), aes(sample_means)) +
  geom_histogram(binwidth = 0.02, color="blue", fill="white") +
  labs(x="Sample mean", y="Count") +
  theme_bw()
```

#### (j)  

**(Question)**What is the numerical value of the expectation $E(\bar{X})$ in your simulation study? What is the numerical value of the variance $Var(\bar{X})$? Give your answers to 4 decimal places.  

**(Answer)**
```{r}
X_bar_expectation <- mean(sample_means) %>% round(4) # using round to get 4 decimal places
X_bar_variance <- var(sample_means) %>% round(4)

cat("The expectation of X_bar is", X_bar_expectation, "\n")
cat("The variance of X_bar is", X_bar_variance)
```

------

Let $f_{\mu, \sigma}: R \rightarrow[0,\infty)$ be the probability density function of a Gaussian random variable with distribution $\mathcal{N}(\mu,\sigma^2)$, so that the population mean is $\mu$ and the population variance is $\sigma^2$.

#### (k)  

**(Question)**Now append to your histogram plot an additional curve of the form $x \mapsto 200 \cdot f_{u,\sigma}(x)$, which displays a rescaled version of the probability density function of a Gaussian random variable with population mean $\mu = E(\bar{X})$ and population variance $\sigma^2=Var(\bar{X})$. You may wish to consider your rescaled density $x \mapsto 200 \cdot f_{u,\sigma}(x)$ displayed for a sequence of x-values between $\mu - 4\sigma$ and $\mu + 4\sigma$ in increments of 0.0001. Make sure that the plot is well-presented and both the histogram and the rescaled density are clearly visible.  

**(Answer)**
```{r}
mu <- X_bar_expectation
sigma <- sqrt(X_bar_variance)
x <- seq(mu-4*sigma, mu+4*sigma, 0.0001) # Set x-values range

norm_df <- data.frame(x=x, pdf=dnorm(x, mean=mu, sd=sigma))

colors <- c("Gaussian pdf"="red", "Simulation"="blue")
fills <- c("Gaussian pdf"="white", "Simulation"="white")

ggplot() +
  # Draw the histogram plot
  geom_histogram(data=data.frame(sample_means=sample_means), aes(x=sample_means, color="Simulation", fill="Simulation"), binwidth = 0.02) +
  # Draw the curve plot
  geom_line(data=norm_df, aes(x=x, y=pdf*200, color="Gaussian pdf"), size=2) +
  scale_color_manual(name="", values = colors) +
  scale_fill_manual(name= "", values = fills) +
  labs(x="X or Sampel mean", y="Count") +
  theme_bw()
```

#### (l)  

**(Question)**Discuss the relationship between the histogram and the additional curve you observe. Can you explain what you observe?  

**(Answer)**In the above case, since the y-axis (count) in the histogram depends on the number of bins affected by the binwidth argument (0.02), the number 200 in $x \mapsto 200 \cdot f_{u,\sigma}(x)$ is used for scaling the value of probability density function within the $x$ range to the value of the histogram. And the scaled density function $200 \cdot f_{u,\sigma}(x)$ (the curve line) well-approximates the simulation (the histogram). According to the central limit theorem, when the sample size is large, no matter whatever the distribution is, the sample means are normally distributed. 

------

### B.3

#### (a)  

**(Question)**Give a formula for the the population mean and variance of an exponential random variable X with parameter $\lambda$.  

**(Answer)**  
$$
\begin{aligned}
E(x) &=\int_{-\infty}^{\infty} x p_{\lambda}(x) d x=\int_{0}^{\infty} x \cdot \lambda e^{-\lambda x} d x \\
&=\left.\left[-x \cdot e^{-\lambda x}\right]\right|_{0} ^{\infty}+\int_{0}^{\infty} e^{-\lambda x} d x \\
&=\left.\left[-\frac{1}{\lambda} e^{-\lambda x}\right]\right|_{0} ^{\infty} \\
&=\frac{1}{\lambda}
\end{aligned}
$$
For the variance, we have $\operatorname{Var}(x)=E\left(x^{2}\right)-E(x)^{2}$. Since we have the $E(x)$, we need to compute $E(x^2)$.

$$
\begin{aligned}
E\left(x^{2}\right) &=\int_{-\infty}^{\infty} x^{2} p_{1}(x) d x=\int_{0}^{\infty} \lambda x^{2} e^{-\lambda x} d x \\
&=\left[-x^{2} e^{-\lambda x}\right]_{0}^{\infty}+\int_{0}^{\infty} x^{2} e^{-\lambda x} d x \\
&=\frac{2}{\lambda} E(x)=\frac{2}{\lambda^{2}} \\
\end{aligned}
$$
Then, we have $\operatorname{Var}(x)=E\left(x^{2}\right)-E(x)^{2}=\frac{2}{\lambda^{2}}-\frac{1}{\lambda^{2}}=\frac{1}{\lambda^{2}}$

#### (b)  

**(Question)**Give a formula for the cumulative distribution function and the quantile function for exponential random variables with parameter $\lambda$.  

**(Answer)**Cumulative distribution function:  
$$
F_{\lambda}(x)=\left\{\begin{array}{ll}
0 & \text { if } x \leq 0 \\
1-e^{-\lambda x} & \text { if } x>0
\end{array}\right.
$$
Quantile function:
$$
\begin{aligned}
F_{\lambda}^{-1}(p) &:=\inf \left\{x \in \mathbb{R}: F_{\lambda}(x) \leq p\right\} = \begin{cases}
 -\infty & \text{ if } p=0 \\
 -\frac{1}{\lambda} \ln (1-p)  & \text{ if } p \in(0,1]
\end{cases}
\end{aligned}
$$

#### (c)  

**(Question)**Suppose that $X_1, ..., X_n$ is an i.i.d sample from the exponential distribution with an unknown parameter $\lambda_0 > 0$. What is the maximum likelihood estimate $\hat{\lambda}_{MLE}$ for $\lambda_0$?    

**(Answer)**Suppose $\ell(\lambda)=\prod_{i=1}^{n}f_{\lambda}(X_i)=\lambda^ne^{-n\lambda\bar{X}}$, then take logarithm of it we have $log\ell(\lambda)=nlog\lambda-n\lambda\bar{X}$ and take derivative of $\lambda$ we have $\frac{\partial}{\partial \lambda} \ell(\lambda)=\frac{n}{\lambda}-n \bar{X}$. Hence, to make $\frac{\partial}{\partial \lambda} \ell(\lambda)=0$, we deduce the maximum likelihood estimate for $\lambda_0$ is given by $\hat{\lambda}_{MLE}=\frac{1}{\bar{X}}$

#### (d)  

**(Question)**Conduct a simulation study to explore the behavior of the maximum likelihood estimator $\hat{\lambda}_{MLE}$ for $\lambda_0$ on simulated data $X_1, ... , X_n$ generated using the exponential distribution. Consider a setting in which $\lambda_0 = 0.01$ and generate a plot of the mean squared error as a function of the sample size. You should consider a sample sizes between 5 and 1000 in increments of 5, and consider 100 trials per sample size. For each trial of each sample size generate a random sample $X_1, ... , X_n$ of the exponential distribution with parameter $\lambda_0 = 0.01$, then compute the maximum likelihood estimate $\hat{\lambda}_{MLE}$ for $\lambda_0$ based upon the corresponding sample. Display a plot of the mean square error of $\hat{\lambda}_{MLE}$ as an estimator for  $\lambda_0$ as a function of the sample size.  
**(Answer)**
```{r}
# For replicability, we set the random seed to 0.
set.seed(0)
lambda_0 <- 0.01
num_trials <- 100
min_sample_size <- 5
max_sample_size <- 1000
sample_size_inc <- 5

simulation_exponential <- crossing(trials=seq(num_trials), sample_size=seq(min_sample_size, max_sample_size, sample_size_inc)) %>% # Generate 100 trials with various sample sizes.
  mutate(sample_x=pmap(.l=list(trials, sample_size), .f=~rexp(.y, rate=lambda_0))) %>% # Generate values randomly using the exponential distribution.
  mutate(lambda_mle=map_dbl(.x=sample_x, ~1/mean(.x))) %>% # Get the average mean of each sample size.
  group_by(sample_size) %>%
  summarise(msq_error=mean((lambda_mle-lambda_0)^2)) # Get he mean squre error of each sample size group.

# Draw a plot for mean square error of estimator lambda_0 
ggplot(data=simulation_exponential, aes(x=sample_size, y=msq_error)) +
  geom_smooth() +
  theme_bw() +
  labs(x="Sample size", y="Mean squre error")
```

------

Now download the csv file entitled “birds_data_EMATM0061” from the Assessment section within Blackboard. The csv file contains synthetic data on arrival times for birds at a bird feeder, collected over a five week period. The species of bird and their arrival time are recorded.

Let’s model the sequence of time differences as independent and identically distributed random variables from an exponential distribution. More, precisely, let $Y_1, Y_2, ... , Y_{n+1}$ denote the sequence of arrival times in seconds. Construct a new sequence of random variables $X_1,...,X_n$ where $X_{i} = Y_{i+1} - Y_{i}$ for each $i=1,...,n$. Model the sequence of differences in arrival times $X_1,...,X_n$ as independent and identically distributed exponential random variables.  

#### (e)  

**(Question)**Compute and display the maximum likelihood estimate of the rate parameter $\hat{\lambda}_{MLE}$.  

**(Answer)**
```{r}
# Load data
birds_data <- read.csv("bird_data_EMATM0061.csv") 
# Get the sequence difference of time by using lead
birds_data <- birds_data %>% mutate(time_diffs=lead(Time)-Time)

time_diffs <- birds_data %>% pull(time_diffs)
lambda_mle <- 1/mean(time_diffs, na.rm=TRUE)
cat("The maximum likelihood estimate for lambda is lambda_0:", lambda_mle)
```

#### (f)  

**(Question)**Can you give a confidence interval for $\lambda_0$ with a confidence level of 95%?  

**(Answer)**Since we want a 95% confidence level for $\lambda_0$, then $\alpha=1-0.95=0.05$. According to Cochran's theorem, we have
$$
\begin{aligned}
&\mathbb{P}\left(-z_{\alpha / 2} < \frac{\bar{X}-\mu}{\mu / \sqrt{n}} < z_{\alpha / 2}\right) \\
&=\mathbb{P}\left(-z_{\alpha / 2} < \sqrt{n} \cdot \frac{1 / \bar{X}-1 / \lambda}{1 / \lambda} < z_{\alpha / 2}\right) \\
&=\mathbb{P}\left(-z_{\alpha / 2} < \sqrt{n} \cdot\left(\frac{\lambda}{\bar{X}}-1\right) < z_{\alpha / 2}\right) \\
&=\mathbb{P}\left(1-\frac{z_{\alpha / 2}}{\sqrt{n}} < \frac{\lambda}{\bar{X}} < 1+\frac{z_{\alpha / 2}}{\sqrt{n}}\right) \\
&=\mathbb{P}\left(\bar{X}\left(1-\frac{z_{\alpha / 2}}{\sqrt{n}}\right) < \lambda < \bar{X}\left(1+\frac{z_{\alpha / 2}}{\sqrt{n}}\right)\right) \\
&=\mathbb{P}\left(\frac{1}{\bar{X}}\left(1-\frac{z_{\alpha / 2}}{\sqrt{n}}\right) < \lambda < \frac{1}{\bar{X}}\left(1+\frac{z_{\alpha / 2}}{\sqrt{n}}\right)\right)
\end{aligned}
$$
then, we know $L_{\alpha}(X_1,X_2,...,X_n)=\frac{1}{\bar{X}}(1-\frac{z_{\alpha / 2}}{\sqrt{n}})$ and $L_{\alpha}(X_1,X_2,...,X_n)=\frac{1}{\bar{X}}(1+\frac{z_{\alpha / 2}}{\sqrt{n}})$, so the cofidence interval is $(\frac{1}{\bar{X}}(1-\frac{z_{\alpha / 2}}{\sqrt{n}}), \frac{1}{\bar{X}}(1+\frac{z_{\alpha / 2}}{\sqrt{n}}))$.

```{r}
confidence_level <- 0.95
alpha <- 1-confidence_level
z_alpha<-qnorm(1-alpha/2) # Quantile function of standard norm distribution.
sample_mn <- mean(time_diffs, na.rm=TRUE)
n <- length(time_diffs)-1 # Eliminate the last NA value.

ci_l<-(1/sample_mn)*(1-z_alpha/sqrt(n)) # Lower limit of confidence interval.
ci_u<-(1/sample_mn)*(1+z_alpha/sqrt(n)) # Upper limit of confidence interval.

cat("In this case, the confidence level is (", ci_l, ",", ci_u, ").")
```


